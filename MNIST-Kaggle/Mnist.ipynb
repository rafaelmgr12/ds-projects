{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmC/t445gMUn59H0asH3IY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaelmgr12/ds-projects/blob/main/MNIST-Kaggle/Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPr0CRRrOtmj"
      },
      "source": [
        "# Digit Recognizer\n",
        "Learn computer vision fundamentals with the famous MNIST data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBqkhtv1Ow6w"
      },
      "source": [
        "## Data Description\n",
        "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
        "\n",
        "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
        "\n",
        "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
        "\n",
        "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\n",
        "\n",
        "```\n",
        "000 001 002 003 ... 026 027\n",
        "028 029 030 031 ... 054 055\n",
        "056 057 058 059 ... 082 083\n",
        " |   |   |   |  ...  |   |\n",
        "728 729 730 731 ... 754 755\n",
        "756 757 758 759 ... 782 783\n",
        "\n",
        "```\n",
        "\n",
        "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
        "\n",
        "Your submission file should be in the following format: For each of the 28000 images in the test set, output a single line containing the ImageId and the digit you predict. For example, if you predict that the first image is of a 3, the second image is of a 7, and the third image is of a 8, then your submission file would look like:\n",
        "\n",
        "```\n",
        "ImageId,Label\n",
        "1,3\n",
        "2,7\n",
        "3,8\n",
        "(27997 more lines)\n",
        "```\n",
        "\n",
        "The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tfskIylAOreP",
        "outputId": "5a6e2757-9353-4462-a950-dc0c46d832c6"
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "if IN_COLAB:\n",
        "  from google.colab import files\n",
        "  files.upload()\n",
        "  ! wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b7.tar.gz\n",
        "  ! tar -xf noisy_student_efficientnet-b7.tar.gz\n",
        "  ! python efficientnet_weight_update_util.py --model b7 --notop --ckpt /content/noisy_student_efficientnet-b7/model.ckpt --o efficientnetb7_notop.h5\n",
        "  ! mkdir ~/.kaggle\n",
        "  ! cp kaggle.json ~/.kaggle/\n",
        "  ! chmod 600 ~/.kaggle/kaggle.json\n",
        "  ! kaggle competitions download -c digit-recognizer\n",
        "  ! unzip test.csv.zip && unzip train.csv.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c0e4a222-225a-418f-9c0a-e14d3fec97ef\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c0e4a222-225a-418f-9c0a-e14d3fec97ef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Saving efficientnet_weight_update_util.py to efficientnet_weight_update_util.py\n",
            "--2021-08-17 12:12:44--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b7.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.213.128, 173.194.214.128, 173.194.215.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.213.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491946092 (469M) [application/octet-stream]\n",
            "Saving to: ‘noisy_student_efficientnet-b7.tar.gz’\n",
            "\n",
            "noisy_student_effic 100%[===================>] 469.16M  64.8MB/s    in 7.3s    \n",
            "\n",
            "2021-08-17 12:12:51 (64.6 MB/s) - ‘noisy_student_efficientnet-b7.tar.gz’ saved [491946092/491946092]\n",
            "\n",
            "2021-08-17 12:12:59.244232: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-17 12:13:01.042529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-17 12:13:01.106282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:01.107267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-08-17 12:13:01.107318: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-17 12:13:01.223514: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-08-17 12:13:01.223640: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-08-17 12:13:01.333539: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-17 12:13:01.369970: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-17 12:13:01.551508: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-17 12:13:01.580066: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-08-17 12:13:01.585644: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-08-17 12:13:01.585809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:01.586840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:01.590755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-08-17 12:13:01.591462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:01.592479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-08-17 12:13:01.592593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:01.593505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:01.594357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-08-17 12:13:01.597375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-17 12:13:04.389931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-17 12:13:04.390005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-08-17 12:13:04.390037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-08-17 12:13:04.390258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:04.391318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:04.392314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-17 12:13:04.393232: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-17 12:13:04.393288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15433 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258080768/258076736 [==============================] - 2s 0us/step\n",
            "check variables match in each block\n",
            "blocks_0 and block1a match.\n",
            "blocks_1 and block1b match.\n",
            "blocks_2 and block1c match.\n",
            "blocks_3 and block1d match.\n",
            "blocks_4 and block2a match.\n",
            "blocks_5 and block2b match.\n",
            "blocks_6 and block2c match.\n",
            "blocks_7 and block2d match.\n",
            "blocks_8 and block2e match.\n",
            "blocks_9 and block2f match.\n",
            "blocks_10 and block2g match.\n",
            "blocks_11 and block3a match.\n",
            "blocks_12 and block3b match.\n",
            "blocks_13 and block3c match.\n",
            "blocks_14 and block3d match.\n",
            "blocks_15 and block3e match.\n",
            "blocks_16 and block3f match.\n",
            "blocks_17 and block3g match.\n",
            "blocks_18 and block4a match.\n",
            "blocks_19 and block4b match.\n",
            "blocks_20 and block4c match.\n",
            "blocks_21 and block4d match.\n",
            "blocks_22 and block4e match.\n",
            "blocks_23 and block4f match.\n",
            "blocks_24 and block4g match.\n",
            "blocks_25 and block4h match.\n",
            "blocks_26 and block4i match.\n",
            "blocks_27 and block4j match.\n",
            "blocks_28 and block5a match.\n",
            "blocks_29 and block5b match.\n",
            "blocks_30 and block5c match.\n",
            "blocks_31 and block5d match.\n",
            "blocks_32 and block5e match.\n",
            "blocks_33 and block5f match.\n",
            "blocks_34 and block5g match.\n",
            "blocks_35 and block5h match.\n",
            "blocks_36 and block5i match.\n",
            "blocks_37 and block5j match.\n",
            "blocks_38 and block6a match.\n",
            "blocks_39 and block6b match.\n",
            "blocks_40 and block6c match.\n",
            "blocks_41 and block6d match.\n",
            "blocks_42 and block6e match.\n",
            "blocks_43 and block6f match.\n",
            "blocks_44 and block6g match.\n",
            "blocks_45 and block6h match.\n",
            "blocks_46 and block6i match.\n",
            "blocks_47 and block6j match.\n",
            "blocks_48 and block6k match.\n",
            "blocks_49 and block6l match.\n",
            "blocks_50 and block6m match.\n",
            "blocks_51 and block7a match.\n",
            "blocks_52 and block7b match.\n",
            "blocks_53 and block7c match.\n",
            "blocks_54 and block7d match.\n",
            "skipping variable normalization/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
            "skipping variable normalization/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
            "skipping variable normalization/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
            "1035/1038 weights updated\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 55% 5.00M/9.16M [00:00<00:00, 34.7MB/s]\n",
            "100% 9.16M/9.16M [00:00<00:00, 44.8MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/6.09M [00:00<?, ?B/s]\n",
            "100% 6.09M/6.09M [00:00<00:00, 55.9MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 83.4MB/s]\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djSO5eDXQGP2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "\n",
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Activation,MaxPooling2D ,Dropout,Conv2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "sns.set(style='white', context='notebook', palette='deep')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFSJrDA0Qmdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fcb9e23-5762-4840-df22-e44b05dbac7b"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "\n",
        "print(\"Data are Ready!!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data are Ready!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0BwvhD1Qs7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6b786b-ae2b-4c57-b32a-285141bb8182"
      },
      "source": [
        "print(f\"Training data size is {train.shape}\\nTesting data size is {test.shape}\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size is (42000, 785)\n",
            "Testing data size is (28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWboD_ofQyY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "96b3d8d7-1131-4c99-9742-bdd1e362bdfc"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdLjphsBQuZW"
      },
      "source": [
        "Y_train = train[\"label\"]\n",
        "X_train = train.drop(labels = [\"label\"], axis = 1) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "1ky6ki5MRpYb",
        "outputId": "f40d0d03-04b2-4f8f-c2f5-83d510f1c90d"
      },
      "source": [
        "g = sns.countplot(Y_train)\n",
        "\n",
        "Y_train.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4684\n",
              "7    4401\n",
              "3    4351\n",
              "9    4188\n",
              "2    4177\n",
              "6    4137\n",
              "0    4132\n",
              "4    4072\n",
              "8    4063\n",
              "5    3795\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCXXpp7VRppj",
        "outputId": "09e05318-f90f-432d-c439-50fe37b4eb6f"
      },
      "source": [
        "X_train.isnull().sum().unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRtx5u-gR3_i",
        "outputId": "3f1cc831-00c3-4890-f774-6b7471484ca9"
      },
      "source": [
        "test.isnull().sum().unique()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaoxrpnfSHR8"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvjwWp6_SFKo"
      },
      "source": [
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "test = test / 255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYUTHFRpSI6A"
      },
      "source": [
        "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
        "X_train = X_train.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvEQ3eplTVgj"
      },
      "source": [
        "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
        "Y_train = to_categorical(Y_train, num_classes = 10)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QINgH1wRTXFO"
      },
      "source": [
        "# Split the train and the validation set for the fitting\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "OxTflmmDTZBI",
        "outputId": "0f711144-0710-43be-af39-e05e348222e9"
      },
      "source": [
        "# Some examples\n",
        "g = plt.imshow(X_train[0][:,:,0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijq7MjydTfgB"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVo00FSMTd_v"
      },
      "source": [
        "# Set the CNN model \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6tjMCQjTlHG",
        "outputId": "93523e93-ed20-4706-8826-07ed7a450173"
      },
      "source": [
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe6i7C8ATpIb"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iLh5DdgTqXD"
      },
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4LL8LS8Tr6b"
      },
      "source": [
        "epochs = 60 \n",
        "batch_size = 64"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJCFgAidTs9i",
        "outputId": "fb5f8f64-b0a7-47bc-ede4-08afead8f394"
      },
      "source": [
        "# With data augmentation to prevent overfitting\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=True,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip= True)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU3TJukzT42C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba1d5c1-513d-4b98-fb85-ea3bd1d9932a"
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
        "                               steps_per_epoch=X_train.shape[0] // batch_size\n",
        "                              , callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "459/459 [==============================] - 42s 58ms/step - loss: 1.7153 - accuracy: 0.3926 - val_loss: 1.3367 - val_accuracy: 0.5468\n",
            "Epoch 2/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.9319 - accuracy: 0.6754 - val_loss: 0.6180 - val_accuracy: 0.7898\n",
            "Epoch 3/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.6891 - accuracy: 0.7664 - val_loss: 0.3498 - val_accuracy: 0.9028\n",
            "Epoch 4/30\n",
            "459/459 [==============================] - 27s 58ms/step - loss: 0.5371 - accuracy: 0.8256 - val_loss: 0.2546 - val_accuracy: 0.9250\n",
            "Epoch 5/30\n",
            "459/459 [==============================] - 27s 60ms/step - loss: 0.4601 - accuracy: 0.8502 - val_loss: 0.2482 - val_accuracy: 0.9284\n",
            "Epoch 6/30\n",
            "459/459 [==============================] - 27s 59ms/step - loss: 0.4191 - accuracy: 0.8689 - val_loss: 0.2001 - val_accuracy: 0.9371\n",
            "Epoch 7/30\n",
            "459/459 [==============================] - 27s 59ms/step - loss: 0.4022 - accuracy: 0.8710 - val_loss: 0.2399 - val_accuracy: 0.9277\n",
            "Epoch 8/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.3852 - accuracy: 0.8809 - val_loss: 0.2892 - val_accuracy: 0.9183\n",
            "Epoch 9/30\n",
            "459/459 [==============================] - 26s 58ms/step - loss: 0.3790 - accuracy: 0.8830 - val_loss: 0.1957 - val_accuracy: 0.9438\n",
            "Epoch 10/30\n",
            "459/459 [==============================] - 27s 60ms/step - loss: 0.3778 - accuracy: 0.8850 - val_loss: 0.2628 - val_accuracy: 0.9273\n",
            "Epoch 11/30\n",
            "459/459 [==============================] - 27s 58ms/step - loss: 0.3827 - accuracy: 0.8862 - val_loss: 0.1683 - val_accuracy: 0.9531\n",
            "Epoch 12/30\n",
            "459/459 [==============================] - 25s 55ms/step - loss: 0.3741 - accuracy: 0.8890 - val_loss: 0.2321 - val_accuracy: 0.9367\n",
            "Epoch 13/30\n",
            "459/459 [==============================] - 26s 56ms/step - loss: 0.3844 - accuracy: 0.8872 - val_loss: 0.2303 - val_accuracy: 0.9330\n",
            "Epoch 14/30\n",
            "459/459 [==============================] - 25s 55ms/step - loss: 0.3962 - accuracy: 0.8866 - val_loss: 0.2947 - val_accuracy: 0.9329\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 15/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.3295 - accuracy: 0.9030 - val_loss: 0.2156 - val_accuracy: 0.9392\n",
            "Epoch 16/30\n",
            "459/459 [==============================] - 26s 56ms/step - loss: 0.3219 - accuracy: 0.9041 - val_loss: 0.3270 - val_accuracy: 0.9106\n",
            "Epoch 17/30\n",
            "459/459 [==============================] - 26s 56ms/step - loss: 0.3289 - accuracy: 0.9040 - val_loss: 0.2915 - val_accuracy: 0.9201\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 18/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.2955 - accuracy: 0.9117 - val_loss: 0.2433 - val_accuracy: 0.9368\n",
            "Epoch 19/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.2918 - accuracy: 0.9133 - val_loss: 0.2258 - val_accuracy: 0.9395\n",
            "Epoch 20/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.2914 - accuracy: 0.9127 - val_loss: 0.2369 - val_accuracy: 0.9359\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 21/30\n",
            "459/459 [==============================] - 26s 56ms/step - loss: 0.2736 - accuracy: 0.9175 - val_loss: 0.2523 - val_accuracy: 0.9334\n",
            "Epoch 22/30\n",
            "459/459 [==============================] - 25s 55ms/step - loss: 0.2775 - accuracy: 0.9179 - val_loss: 0.2848 - val_accuracy: 0.9218\n",
            "Epoch 23/30\n",
            "459/459 [==============================] - 27s 58ms/step - loss: 0.2770 - accuracy: 0.9176 - val_loss: 0.2072 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 24/30\n",
            "459/459 [==============================] - 27s 59ms/step - loss: 0.2675 - accuracy: 0.9200 - val_loss: 0.2249 - val_accuracy: 0.9390\n",
            "Epoch 25/30\n",
            "459/459 [==============================] - 27s 58ms/step - loss: 0.2681 - accuracy: 0.9208 - val_loss: 0.2238 - val_accuracy: 0.9406\n",
            "Epoch 26/30\n",
            "459/459 [==============================] - 27s 59ms/step - loss: 0.2755 - accuracy: 0.9182 - val_loss: 0.2525 - val_accuracy: 0.9320\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 27/30\n",
            "459/459 [==============================] - 27s 59ms/step - loss: 0.2601 - accuracy: 0.9238 - val_loss: 0.2516 - val_accuracy: 0.9307\n",
            "Epoch 28/30\n",
            "459/459 [==============================] - 27s 58ms/step - loss: 0.2594 - accuracy: 0.9215 - val_loss: 0.2445 - val_accuracy: 0.9339\n",
            "Epoch 29/30\n",
            "459/459 [==============================] - 26s 56ms/step - loss: 0.2574 - accuracy: 0.9221 - val_loss: 0.2448 - val_accuracy: 0.9329\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 30/30\n",
            "459/459 [==============================] - 26s 57ms/step - loss: 0.2609 - accuracy: 0.9225 - val_loss: 0.2337 - val_accuracy: 0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yITDzQByUKSP"
      },
      "source": [
        "# predict results\n",
        "results = model.predict(test)\n",
        "\n",
        "# select the indix with the maximum probability\n",
        "results = np.argmax(results,axis = 1)\n",
        "\n",
        "results = pd.Series(results,name=\"Label\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxO2d7p7EvoD"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raGEj6SaEuwQ"
      },
      "source": [
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
        "\n",
        "submission.to_csv(\"submission.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3LGNMe2E4vl"
      },
      "source": [
        "! kaggle competitions submit -c digit-recognizer -f submission.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}